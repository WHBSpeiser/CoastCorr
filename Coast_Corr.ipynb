{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c104b1",
   "metadata": {},
   "source": [
    "# Coast Corr\n",
    "\n",
    "### Here you can calculate per-pixel statistics of a imagery catalogue converted to CSV's with environmental monitoring data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8d6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coast_corr import coast_corr, coast_corr_functions\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "import ipywidgets\n",
    "import osmnx as ox\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl, basemaps, basemap_to_tiles\n",
    ")\n",
    "import folium\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a9b87b",
   "metadata": {},
   "source": [
    "## Select folder containing imagery csv files, select satellite type, select environmental parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866d1668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bfe4f7b63a4b55ba493ea2929b9756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Satellite:', options=('Sentinel 2', 'Landsat 5', 'Landsat 7', 'Landsat 8', 'MODIS Aqua', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f223bc77f443b99d49c3fe3b38585b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Environmental Data:', index=1, options=('Modeled Wave Energy', 'River Discharge', 'Ocean W…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = Tk()\n",
    "root.withdraw()\n",
    "csv_folder = filedialog.askdirectory()\n",
    "\n",
    "\n",
    "\n",
    "sat=ipywidgets.Select(\n",
    "    options=['Sentinel 2', 'Landsat 5', 'Landsat 7', 'Landsat 8','MODIS Aqua','MODIS Terra'],\n",
    "    value='Sentinel 2',\n",
    "    # rows=10,\n",
    "    description='Satellite:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(sat)\n",
    "\n",
    "\n",
    "env_dat=ipywidgets.Select(\n",
    "    options=['Modeled Wave Energy','River Discharge', 'Ocean Water Level','HF Radar'],\n",
    "    value='River Discharge',\n",
    "    description='Environmental Data:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(env_dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c3bc5",
   "metadata": {},
   "source": [
    "### Here we check to see if you have already combined all of the CSV's of interest to create a pixel value csv. If not, they are combined, if so, they are accessed.\n",
    "\n",
    "#### In the case that this is your first time combining them, it could take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25439921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "reading combined csv\n"
     ]
    }
   ],
   "source": [
    "coast_corr_functions.catalogue_csv(csv_folder)\n",
    "\n",
    "os.chdir(csv_folder)\n",
    "band=csv_folder.split(\"/\")[len(csv_folder.split(\"/\"))-1]\n",
    "path_parent = os.path.dirname(csv_folder)\n",
    "csv_fold=path_parent+'/coastcorr_csv'\n",
    "res_out=csv_fold+'/'+band+\"_combined_csv.csv\"\n",
    "\n",
    "print(\"reading combined csv\")\n",
    "\n",
    "sr_df=pd.read_csv(res_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233e37d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if env_dat.value == 'River Discharge':\n",
    "    # from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "\n",
    "    def download_file_from_google_drive(id, destination):\n",
    "        URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "        session = requests.Session()\n",
    "\n",
    "        response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "        token = get_confirm_token(response)\n",
    "\n",
    "        if token:\n",
    "            params = { 'id' : id, 'confirm' : token }\n",
    "            response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "        save_response_content(response, destination)    \n",
    "\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, destination):\n",
    "        \"\"\"\n",
    "        response = filename for input\n",
    "        destination = filename for output\n",
    "        \"\"\"    \n",
    "        CHUNK_SIZE = 32768\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "            for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "\n",
    "\n",
    "\n",
    "    DATASET_ID = '1Gh9NcqS0g1VI9EPMglbOl3_Cg8MFqPfb'\n",
    "\n",
    "\n",
    "    destination = '../data.shp'\n",
    "    download_file_from_google_drive(DATASET_ID, destination)\n",
    "    env_df= pd.read_csv(destination)\n",
    "    env_df = gpd.GeoDataFrame(\n",
    "    env_df, geometry=gpd.points_from_xy(env_df.LNG_GAGE, env_df.LAT_GAGE))\n",
    "    \n",
    "\n",
    "     # Make an empty map\n",
    "    m = folium.Map(location=[35,-124.4], tiles= \"Stamen Terrain\", zoom_start=4)\n",
    "\n",
    "    # Show the map\n",
    "    m\n",
    "\n",
    "    \n",
    "    for i in range(0,len(env_df)):\n",
    "        folium.Marker(\n",
    "            location=[env_df.iloc[i]['LAT_GAGE'], env_df.iloc[i]['LNG_GAGE']],\n",
    "            popup=env_df.iloc[i]['STAID'],\n",
    "\n",
    "           ).add_to(m)\n",
    "    m\n",
    "\n",
    "if env_dat.value == 'Modeled Wave Energy':\n",
    "    # from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "\n",
    "    def download_file_from_google_drive(id, destination):\n",
    "        URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "        session = requests.Session()\n",
    "\n",
    "        response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "        token = get_confirm_token(response)\n",
    "\n",
    "        if token:\n",
    "            params = { 'id' : id, 'confirm' : token }\n",
    "            response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "        save_response_content(response, destination)    \n",
    "\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, destination):\n",
    "        \"\"\"\n",
    "        response = filename for input\n",
    "        destination = filename for output\n",
    "        \"\"\"    \n",
    "        CHUNK_SIZE = 32768\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "            for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "                    \n",
    "\n",
    "\n",
    "    DATASET_ID = '11lbhCV-R3dkeioE6RHfiwuLMqhlWNAft'\n",
    "\n",
    "\n",
    "    destination = '../data.csv'\n",
    "    download_file_from_google_drive(DATASET_ID, destination)\n",
    "    env_df= pd.read_csv(destination)\n",
    "    \n",
    "    env_df = gpd.GeoDataFrame(\n",
    "    env_df, geometry=gpd.points_from_xy(env_df.LNG_GAGE, env_df.LAT_GAGE))\n",
    "\n",
    "     # Make an empty map\n",
    "    m = folium.Map(location=[35,-124.4], tiles= \"Stamen Terrain\", zoom_start=4)\n",
    "\n",
    "    # Show the map\n",
    "    m\n",
    "    \n",
    "    env_df=gpd.clip(env_df, polygon, keep_geom_type=False)\n",
    "\n",
    "\n",
    "    for i in range(0,len(env_df)):\n",
    "       folium.Marker(\n",
    "          location=[env_df.iloc[i]['LAT_GAGE'], env_df.iloc[i]['LNG_GAGE']],\n",
    "          popup=env_df.iloc[i]['STATID'],\n",
    "\n",
    "       ).add_to(m)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "station=ipywidgets.Text(\n",
    "    value='Name of Station',\n",
    "    placeholder='Type something',\n",
    "    description='Station:',\n",
    "    disabled=False\n",
    ")\n",
    "display(station)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b571939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coast_corr_functions.get_data(env_dat.value,station.value, csv_folder)\n",
    "\n",
    "if env_dat.value == 'River Discharge':\n",
    "    collector='USGS'\n",
    "    site_path=os.path.dirname(os.path.dirname(os.path.dirname(csv_folder)))\n",
    "    env_fold=site_path+'/environmental_data_csv'\n",
    "    collec_fold=env_fold+'/'+collector\n",
    "    file_out= collec_fold+\"/\"+station.value+'.csv'\n",
    "    env_df=pd.read_csv(file_out)\n",
    "    print('downloaded data read')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6507460",
   "metadata": {},
   "source": [
    "# Calculate your stats here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e73ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_choice=ipywidgets.Select(\n",
    "    options=['Mean','Median', 'Standard Deviation','Spearman Correlation','Linear Correlation'],\n",
    "    value='Mean',\n",
    "    description='Statistic for Composite:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(stat_choice)\n",
    "\n",
    "binning=ipywidgets.Text(\n",
    "    value='24',\n",
    "    placeholder='Type something',\n",
    "    description='Data Bin Hours:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(binning)\n",
    "\n",
    "\n",
    "int0=ipywidgets.Text(\n",
    "    value='.95',\n",
    "    placeholder='Type something',\n",
    "    description='Percentile Upper:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(int0)\n",
    "\n",
    "int1=ipywidgets.Text(\n",
    "    value='1.0',\n",
    "    placeholder='Type something',\n",
    "    description='Percentile Lower:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(int1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040acf49",
   "metadata": {},
   "source": [
    "## Navigate to source imagery folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c19cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.withdraw()\n",
    "imgs = filedialog.askdirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coast_corr_functions.data_binner(env_df, sr_df, binning.value, station.value, csv_folder, sat.value, env_dat.value)\n",
    "\n",
    "if env_dat.value=='River Discharge':\n",
    "        freq=binning.value+'h'\n",
    "        collector='USGS'\n",
    "        site_path=os.path.dirname(os.path.dirname(os.path.dirname(csv_folder)))\n",
    "        env_fold=site_path+'/environmental_data_csv'\n",
    "        collec_fold=env_fold+'/'+collector\n",
    "        file_out= collec_fold+\"/\"+ station.value+'_'+freq+'.csv'\n",
    "        df_data=pd.read_csv(file_out)\n",
    "        \n",
    "        if stat_choice.value== 'Mean':\n",
    "            points=(df_data.columns[3:len(df_data.columns)-21]).tolist()\n",
    "            df_fin = pd.DataFrame(columns=['points','stat'])\n",
    "            i=0\n",
    "            value=[]\n",
    "            print('Calculating mean at each position')\n",
    "            for i in range(0,len(points)):\n",
    "                try:\n",
    "                    stat=np.nanmean(df_data.iloc[:,i+3:i+4])\n",
    "                    value.append(stat)\n",
    "                except:\n",
    "                    stat=np.nan\n",
    "                    value.append(stat)        \n",
    "                    \n",
    "        df_fin = pd.DataFrame(columns=['points','stat'])\n",
    "        df_fin['points']=points\n",
    "        df_fin['stat']=value\n",
    "        df_fin['lon']=df_fin.points.str.split('(', expand=True)[1].str.split(' ',expand=True)[0]\n",
    "        df_fin['lat']=df_fin.points.str.split('(', expand=True)[1].str.split(' ',expand=True)[1].str.split(')', expand=True)[0]\n",
    "        df_fin['lat']=df_fin['lat'].astype(float)\n",
    "        df_fin=df_fin[df_fin['lat']>0]\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "raster_creater(df_fin,imgs,csv_folder,env_dat.value,stat_choice.value,int0.value,int1.value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
